{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "3705555de6e98b516f0798602772c05a16f2cecb14601760733bab7b135c9c9a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import nltk \n",
    "import pprint\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the csv created in the previous step, I will create a csv only with the appids. \n",
    "column_names = [\"Timestamp\", \"AppID\", \"Title\", \"Current_Players\", \"Peak_Players\"]\n",
    "df = pd.read_csv(\"SteamTop100byTime.csv\", names=column_names)\n",
    "appids_list = df.AppID.to_list()\n",
    "df.to_csv('top100appids.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will define the function get_reviews which will use the request reviews function from the STEAM api. \n",
    "def get_reviews(appid, params): \n",
    "        url_start = 'https://store.steampowered.com/appreviews/'\n",
    "        try:\n",
    "            response = requests.get(url=url_start+str(appid), params=params, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        except:\n",
    "                return {'reviews' : []}\n",
    "        return response.json() # return data extracted from the json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this creates an empty list for reviews, the rest are parameters, it includes 100 reviews per game, sorted by helpfulness. \n",
    "reviews = []\n",
    "cursor = '*'\n",
    "params = { # https://partner.steamgames.com/doc/store/getreviews\n",
    "    'json' : 1,\n",
    "    'filter' : 'all', # sort by: recent, updated, all (helpfulness)\n",
    "    'language' : 'english', # https://partner.steamgames.com/doc/store/localization\n",
    "    'day_range' : 9223372036854775807, # shows reviews from all time\n",
    "    'review_type' : 'all', # all, positive, negative\n",
    "    'purchase_type' : 'all', # all, non_steam_purchase, steam\n",
    "    'num_per_page' : 100,\n",
    "    'cursor' : '*'.encode()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a blank dictionary and calls the appids_list created in the second step. for each app id in the list of ids, it will get the reviews. The app_dict of each app_id is stored in L\n",
    "\n",
    "app_dict = {}\n",
    "app_ids = (appids_list)\n",
    "for i, app_id in enumerate(app_ids):\n",
    "    l = get_reviews(app_id, params)[\"reviews\"]\n",
    "    app_dict[app_id] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['ï»¿graph', 'linear ', 'matrix', 'mappings', 'spatial', 'static', 'metric', 'temporal', 'partition', 'calculus', 'robust', 'transactions', 'switch', 'transaction', 'predicate', 'probabilistic', 'latency', 'workload', 'prefix', 'configuration', 'feasible', 'corollary', 'maximal', 'scaling', 'geometry', 'fragment', 'predicates', 'processor', 'weighted', 'geometric', 'verify', 'array', 'fraction', 'heuristic', 'generic', 'hybrid', 'overview', 'verification', 'alignment', 'illumination', 'symmetric', 'connectivity', 'exponential', 'fragment', 'simulations', 'latent', 'cognitive', 'rendering', 'merge', 'differential', 'template', 'additionally', 'default', 'annotations', 'annotation', 'authentication', 'auxiliary', 'equilibrium', 'inverse', 'trajectory', 'trajectories', 'conjunction', 'mapped', 'horizontal', 'anomaly', 'redundant', 'annotated', 'dependence', 'regression', 'disparity', 'correspondences', 'bottleneck', 'congruence', 'diagram', 'probing', 'primitive', 'divergence', 'incremental', 'probe', 'graphics', 'collaborative', 'generator', 'spectrum', 'navigation', 'sequent', 'heterogeneous', 'quantitative', 'axioms', 'logics', 'parallelism', 'locality', 'manifold', 'subjective', 'viewpoint', 'suffices', 'aligned', 'computationally', 'identifier', 'symmetry', 'interpolation', 'verified', 'span', 'corruption', 'negligible', 'positives', 'containment', 'tradeoff', 'conservative', 'stationary', 'instrumentation', 'profiles', 'electronic', 'homogeneous', 'decoding', 'diffusion', 'generalize', 'localization', 'synthesis', 'substitutions', 'delete', 'artifact', 'arrays', 'equivalently', 'foster', 'assertion', 'asymmetric', 'descendant', 'programmer', 'redundancy', 'variational', 'affinity', 'converge', 'templates', 'equalities', 'controllers', 'contour', 'inter-', 'centralized', 'cumulative', 'vulnerable', 'fusion', 'legitimate', 'precondition', 'timing', 'invocation', 'simulator', 'priority', 'simultaneous', 'directory', 'proxy', 'virtualization', 'propagate', 'estimator', 'deletions', 'intitialize', 'collaboration', 'salient', 'budget', 'scaled', 'transparent', 'vocabulary', 'premise', 'supervised', 'vulnerability', 'statically', 'predictor', 'spatially', 'objectives', 'emergency', 'incurs', 'weaker', 'proximity', 'inverted', 'tangent', 'invalid', 'vulnerabilities', 'terminology', 'replicated', 'negation', 'acceleration', 'assertions', 'huge', 'activation', 'diffuse', 'aforementioned', 'focal', 'cardinal', 'singular', 'formalize', 'incrementally', 'epoch', 'tolerance', 'causal', 'informative', 'duality', 'counterpart', 'formalized', 'latencies', 'asymptotically', 'entails', 'fragmentation', 'designated', 'quantification', 'activated', 'resilient', 'fluid', 'embeddings', 'valuations', 'invocations', 'adjacency', 'feasibility', 'incur', 'projective', 'corrupted', 'dissemination', 'developer', 'generative ', 'personalized', 'authenticated', 'fractional', 'rationale', 'elaborate', 'predictors', 'selectivity', 'incurred', 'contiguous', 'convergent', 'formalism', 'plausible', 'abort', 'enterprise', 'align', 'infeasible', 'adaptivity', 'blurred ', 'signaling', 'accuracies', 'quantified', 'viewpoints', 'identifiers', 'degrade', 'instantaneous', 'conjecture', 'verifier', 'programmable', 'ascending', 'obstacle', 'obstacles', 'termed', 'concise', 'prominent', 'characterizing', 'temporally', 'matchings', 'causality', 'elapsed', 'prescribed', 'resolutions', 'spurious', 'inheritance', 'numeric', 'transparency', 'imperative', 'preconditions', 'simplifying', 'resilience', 'tackle', 'synthesized', 'ample', 'alarm', 'descendants', 'inherited', 'localize', 'decode', 'formalization', 'optimally', 'equivalences', 'geographic', 'enumerate', 'parentheses', 'associative', 'degrade', 'devise', 'tolerate', 'intractable', 'increments', 'credibility', 'intersections', 'augment', 'extrapolation', 'verifies', 'distribution', 'recognizable', 'truncated', 'dialog', 'emulated', 'positional', 'repository', 'biological', 'imports', 'quantitative', 'variances', 'antecedent', 'consolidation', 'proxies', 'authenticate', 'readability', 'replicate', 'modulation', 'amenable', 'adaptively', 'condition', 'conservatively', 'augmenting', 'iterate', 'articulated', 'holistic', 'robustly', 'simplifies', 'spontaneous', 'stance', 'conjunctions', 'hereafter', 'skewed', 'subtraction', 'portable', 'repetition', 'taxonomy']\n"
     ]
    }
   ],
   "source": [
    "#create a list of STEM words from a .txt file. The list is called STEM_words\n",
    "import csv\n",
    "\n",
    "STEM_words = []\n",
    "with open('STEM_words.csv', newline='') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        STEM_words.append(row[0])\n",
    "\n",
    "print(STEM_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary called app_freq which will tokenize all the words in the review and match them to the STEM_words list. \n",
    "app_freq = {}\n",
    "scraped_apps = list(app_dict.keys())\n",
    "for a in scraped_apps:\n",
    "    rl = app_dict[a]\n",
    "    d = {sw:0 for sw in STEM_words}\n",
    "    for i,r in enumerate(rl):\n",
    "        rev_str = r[\"review\"]\n",
    "        words = nltk.word_tokenize(rev_str)\n",
    "        lwords = [w.lower() for w in words]\n",
    "        for sw in STEM_words:\n",
    "            if sw in lwords:\n",
    "                #print(a, i,\"found\", sw)\n",
    "                d[sw] = d[sw] + 1\n",
    "    app_freq[a] = d\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe from the app_freq dictionary and save it as a CSV file.     \n",
    "\n",
    "df = pd.DataFrame.from_dict(app_freq, orient=\"index\")\n",
    "df.append(df.sum().rename('Total'))\n",
    "df.to_csv('technicalwords.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}